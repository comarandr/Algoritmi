\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx} % Required for inserting images
%before \begin
\usepackage{amssymb} %per i simboli matematici
\usepackage{mathtools} %per simboli 
\usepackage{listings} %per scrivere codice
\usepackage[boxruled,vlined]{algorithm2e}
\lstset{
  basicstyle=\ttfamily,
  mathescape
}
\usepackage{color} %per colorare il codice
\usepackage[hidelinks]{hyperref} %per i link
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = black, %Colour of internal links
  citecolor   = red %Colour of citations
}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% COPERTINA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Algoritmi \& Strutture Dati}
\author{Andrea Comar}
\date{October 2024}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CONCETTI MATEMATICI %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Concetti Matematici}
\section{Notazione asintotica} %%% NOTAZIONE ASINTOTICA %%%
Strumento per confrontare quale funzioni divergono all'infinito più velocemente. Metodo di confronto 
tra funzioni di costo degli algoritmi. Caratteristiche:
\begin{itemize}
    \item $f: \mathbb{N} \rightarrow \mathbb{R^+}$
    \item funzioni \textbf{monotone crescenti}
    \item $lim_{n \rightarrow \infty} \ f(n) = \infty$ (divergenti)
\end{itemize}

In breve la notazione asintotica si basa su tre simboli:
\begin{itemize}
    \item $O$ (O-grande): rappresenta il caso peggiore, ovvero il \textbf{limite asintotico superiore}. ~ "cresce al più come"
    \item $\Omega$ (Omega): rappresenta il caso migliore, ovvero il \textbf{limite asintotico inferiore} ~ "cresce al meno come"
    \item $\Theta$ (theta): rappresenta il caso medio, ovvero il \textbf{limite asintotico stretto} ~ "stesso ordine di grande"
\end{itemize}
La notazione asintotica si fonda sul concetto di limite, in particolare sul \textbf{limite del rapporto}. Di base possiamo riscri


\subsection{Notazione O-grande (e o-piccolo)} %%%%%%%%%%%%%%%%%%%%%%% NOTAZIONE O-GRANDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Notazione O-grande $O$} Abbiamo due definizioni equivalenti:
\begin{itemize}
\item $O(g(n))=\{f(n)| \ \exists c > 0 \ \exists \bar{n} \ \forall n \geq \bar{n} \ f(n) \leq c \cdot g(N)\}$ 
\item Date $f,g : \mathbb{N} \rightarrow \mathbb{R^+}$ \textbf{monotone crescenti}, diciamo che $f(n) \in O(g(n))$ se $\exists c > 0 \ e \ \exists \bar{n} : \forall n \geq \bar{n} \ f(n) \leq c \cdot g(n)$
\end{itemize}
Di base entrambe fanno riferimento al concetto di \textbf{limite del rapporto} 
\begin{itemize}
    \item $\displaystyle \limsup_{n \to \infty} \lvert \frac{f(n)}{g(n)} \rvert < \infty \Leftrightarrow f(n) = O(g(n))$ 
\end{itemize}
Diciamo che g(n) domina f(n), ovvero f(n) ha un ordine di grandezza minore o uguale a g(n).
\paragraph{notazione o-piccolo $o$} Se nelle definizioni invece di $\exists c$ vale per $\forall c$  si parla di notazione o-piccolo. Quindi vale il seguente limite:
\begin{itemize}
    \item $\displaystyle \lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = 0 \Leftrightarrow f(n) = o(g(n))$
\end{itemize}
Di conseguenza $f(n) = o(g(n)) \Rightarrow f(n) = O(g(n))$, NON il contrario.
\subsection{Notazione Omega-grande (e omega-piccolo)} %%%%%%%%%%%%%%%%%% NOTAZIONE OMEGA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Notazione Omega-grande $\Omega$} Abbiamo due definizioni equivalenti:
\begin{itemize}
\item $\Omega(g(n))=\{f(n)| \ \exists c > 0 \ \exists \bar{n} \in \mathbb{N} \ \forall n \geq \bar{n} \ f(n) \geq c \cdot g(N)\}$ 
\item Date $f,g : \mathbb{N} \rightarrow \mathbb{R^+}$ \textbf{monotone crescenti}, diciamo che $f(n) \in \Omega(g(n))$ se $\exists c > 0 \ e \ \exists \bar{n} : \forall n \geq \bar{n} \ f(n) \geq c \cdot g(n)$
\end{itemize}
Di base entrambe fanno riferimento al concetto di \textbf{limite del rapporto}
\begin{itemize}
    \item $\displaystyle \liminf_{n \rightarrow \infty} \lvert \frac{f(n)}{g(n)} \rvert > 0 \Leftrightarrow f(n) = \Omega(g(n))$
\end{itemize}
\paragraph{notazione omega-piccolo $\omega$} Se nelle definizioni invece di $\exists c$ vale per $\forall c$  si parla di notazione omega-piccolo. Quindi vale il seguente limite:
\begin{itemize}
    \item $\displaystyle \lim_{n\to\infty} \frac{f(n)}{g(n)} = \infty \Leftrightarrow f(n) = \omega(g(n))$
\end{itemize}
Di conseguenza $f(n) = \omega(g(n)) \Rightarrow f(n) = \Omega(g(n))$, NON il contrario.

\subsection{Notazione Theta} %%%%%%%%%% NOTAZIONE THETA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Notazione Theta $\Theta$} Abbiamo due definizioni equivalenti:
\begin{itemize}
\item $\Theta(g(n))=\{f(n)| \ \exists c_1, c_2 > 0 \ \exists \bar{n} \in \mathbb{N} \ \forall n \geq \bar{n} \ c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)\}$
\item Date $f,g : \mathbb{N} \rightarrow \mathbb{R^+}$ \textbf{monotone crescenti}, diciamo che $f(n) \in \Theta(g(n))$ se $\exists c_1, c_2 > 0 \ e \ \exists \bar{n} : \forall n \geq \bar{n} \ c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)$
\end{itemize}

Di base entrambe fanno riferimento al concetto di \textbf{limite del rapporto}
\begin{itemize}
    \item $\displaystyle 0 < \liminf_{n\to\infty} \lvert \frac{f(n)}{g(n)}\rvert \leq \limsup_{n\to\infty}\lvert \frac{f(n)}{g(n)}\rvert \leq \infty$
\end{itemize}

\paragraph{notazione $\sim$}  Se le due funzioni sono sia $o$ che $\Theta$ allora si può scrivere $f(n) \sim g(n)$ e vale che:
\begin{itemize}
    \item $\displaystyle \lim_{n \rightarrow \inf} \frac{f(n)}{g(n)} = c , c \neq 0 \in \mathbb{R} \Leftrightarrow f(n) \sim g(n)$
\end{itemize}
Di conseguenza $f(n) \sim g(n) \Rightarrow f(n) = \Theta(g(n))$, NON il contrario. \newline
NOTA: per parlare di equivalenza asintotica $c$ dovrebbe essere esattamente uguale a 1.
\newpage

\subsection{Proprietà di base} %%%%%%%%%%%%%%%% PROPRIETA' %%%%%%%%%%%%%%%%%%%%%%%%%%%%
Se f(n) è $O$ di g(n) allora g(n) è $\Omega$ di f(n). Significa che g(n) cresce di più asintoticamente.
\begin{itemize}
\item $f(n) \in O(g(n)) \ \Leftrightarrow \ g(n) \in \Omega(f(n))$
\end{itemize}
Se f(n) cresce allo stesso modo di g(n), g(n) rappresenta sia il limite superiore che inferiore.
\begin{itemize}
\item $f(n) \in \Theta(g(n)) \ \Leftrightarrow \ f(n) \in O(g(n)) \ \wedge \ f(n) \in \Omega(g(n))$
\end{itemize}
Analogamente per la notazione o-piccolo e omega-piccolo:
\begin{itemize}
\item $f(n) \in o(g(n)) \ \Leftrightarrow \ g(n) \in \omega(f(n))$
\end{itemize}
Infine due funzioni piuttosto basilari, ovvero:
\begin{itemize}
    \item $f=O(f)$ 
    \item $f = o(f) \Rightarrow f \equiv 0 $
\end{itemize}

\subsection{Comportamento rispetto alle operazioni} %%%%%%%%%%%%%%%%% REGOLE %%%%%%%%%%%%%%%%%%
Le seguenti regole valgono indistimamente per $O$, $\Omega$ e $\Theta$, si ereditano dalle proprietà dei limiti.
\paragraph{Abuso di notazione}
\begin{itemize}
    \item $f(x) = O(g(x))$ non è corretto in quanto non sono effettivamente uguali, tuttavia si usa per comodità al posto di $f(x) \in O(g(x))$
\end{itemize}
\paragraph{Transitività}
\begin{itemize}
    \item $f \in O(g) \ \wedge \ g \in O(h) \ \Rightarrow \ f \in O(h)$
    \item $f \in \Omega(g) \ \wedge \ g \in \Omega(h) \ \Rightarrow \ f \in \Omega(h)$
    \item $f \in \Theta(g) \ \wedge \ g \in \Theta(h) \ \Rightarrow \ f \in \Theta(h)$
    \item $f \in o(g) \ \wedge \ g \in o(h) \ \Rightarrow \ f \in o(h)$
    \item $f \in \omega(g) \ \wedge \ g \in \omega(h) \ \Rightarrow \ f \in \omega(h)$
\end{itemize}

\paragraph{Additività}
\begin{itemize}
    \item $f \in O(h) \ \wedge \ g \in O(h) \ \Rightarrow \ f + g \in O(h)$
    \item $f \in \Omega(h) \ \wedge \ g \in \Omega(h) \ \Rightarrow \ f + g \in \Omega(h)$
    \item $f \in \Theta(h) \ \wedge \ g \in \Theta(h) \ \Rightarrow \ f + g \in \Theta(h)$
\end{itemize}
\paragraph{Riflessività}
\begin{itemize}
    \item $f \in O(f)$, con abuso di notazione $f(n) = O(f(n))$
    \item $f \in \Omega(f)$, con abuso di notazione $f(n) = \Omega(f(n))$
    \item $f \in \Theta(f)$, con abuso di notazione $f(n) = \Theta(f(n))$
\end{itemize}
\paragraph{Simmetria}
\begin{itemize}
    \item $f = \Theta(g) \ \Rightarrow \ g = \Theta(f)$
\end{itemize}
\paragraph{Simmetria trasposta}
\begin{itemize}
    \item $f = O(g) \ \Rightarrow \ g = \Omega(f)$
    \item $f = o(g) \ \Rightarrow \ g = \omega(f)$
\end{itemize}
\paragraph{Somma di due funzioni}: 
\begin{itemize}
    \item $f_1 \in O(g_1) \ \wedge \ f_2 \in O(g_2) \Rightarrow f_1 + f_2 \in O(g_1 + g_2)$
    \item $f_1 \in \Omega(g_1) \ \wedge \ f_2 \in \Omega(g_2) \ \Rightarrow \ f_1 + f_2 \in \Omega(g_1 + g_2)$
    \item $f_1 \in \Theta(g_1) \ \wedge \ f_2 \in \Theta(g_2) \ \Rightarrow \ f_1 + f_2 \in \Theta(g_1 + g_2)$
\end{itemize}

\paragraph{Prodotto di due funzioni}

\begin{itemize}
    \item $f_1 \in O(g_1) \ \wedge \ f_2 \in O(g_2) \ \Rightarrow \ f_1 \cdot f_2 \in O(g_1 \cdot g_2 )$
    \item $f_1 \in \Omega(g_1) \wedge f_2 \in \Omega(g_2) \ \Rightarrow \ f_1 \cdot f_2 \in \Omega(g_1 \cdot g_2)$
    \item $f_1 \in \Theta(g_1) \ \wedge \ f_2 \in \Theta(g_2) \ \Rightarrow \ f_1 \cdot f_2 \in \Theta(g_1 \cdot g_2)$
\end{itemize}

Le precedenti regole NON valgono per operazioni di sottrazione e divisione.

\paragraph{Costante moltiplicatica}
\begin{itemize}
    \item $O(c \cdot f) = O(f)$, $\forall c \in \mathbb{R}_0$
    \item $\Omega(c \cdot f) = \Omega(f)$, $\forall c \in \mathbb{R}_0$
    \item $\Theta(c \cdot f) = \Theta(f)$, $\forall c \in \mathbb{R}_0$
\end{itemize}
Semplicemente possiamo dire che la costante moltiplicativa non influisce sul comportamento asintotico.

\paragraph{Trascurare termini additivi di ordine inferiore}
\begin{itemize}
    \item $g = O(f) \ \Rightarrow \ f + g = \Theta(f)$
\end{itemize}
Ovver possiamo considerare unicamente il termine di ordine maggiore.

\paragraph{Trascurare le costanti moltiplicative} 
\begin{itemize}
    \item $\forall a > 0 \ \Rightarrow \ a \cdot f = \Theta(f)$
\end{itemize}
\newpage

\section{Cenni utili sui limiti}

\section{Stime di Somme}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ALGORITMI %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Algoritmi}
\section{Tabella riassuntiva costi temporali} %%%%%%%%%%%%%%%% TABELLA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{tabular}{|c |c| c |c |c|}
    \hline
    \textbf{Algoritmo} & \textbf{peggiore} & \textbf{ migliore medio} & \textbf{stabile } & \textbf{Inplace}\\
    \hline
    \hyperlink{insertionsort}{\textbf{Insertion Sort}} & $\Theta(n^2)$ & $\Theta(n)$ & stabile & inplace\\
    \hyperlink{merge}{Merge} & $\Theta(n)$ & $\Theta(n)$ & stabile & non inplace\\
    \hyperlink{mergesort}{\textbf{Merge Sort}}& $\Theta(n \log n)$ & $\Theta(n \log n)$ & & non inplace\\
    \hyperlink{heapify}{Heapify} & $O(\log n)$ & & & \\
    \hyperlink{buildmaxheap}{Build Max Heap} & $\Theta(n)$ & & & inplace \\ 
    \hyperlink{heapsort}{\textbf{Heap Sort}} & $O(n \log n)$ & & non stabile & \\
    Quick Sort & $\Theta(n^2)$ & $\Theta(n \log n)$ & & inplace \\
    \hyperlink{selection}{Selection Sort} & $\Theta(n^2)$ & & & \\
    \hyperlink{countingsort}{Counting Sort} & $\Theta(n^2)$  & $\Theta(n+k)$, $k \in O$(n) & stabile & non inplace\\    
    Radix Sort &  & $d \cdot \Theta(n)$ & stabile & inplace \\
    Bucket Sort & $\Theta(n^2)$ & $\Theta(n)$ & dipende & non inplace\\
    \hline

\end{tabular}
\newpage

\section{Algoritmi di ordinamento e costruzione}
\paragraph{PROBLEMA} Problema data una sequenza a1, a2, ..., an di numeri, trovare una permutazione tale che 
$a1 \leq a2  \leq ... \leq an$. \newline
Soluzioni:
\hypertarget{insertionsort}{} \subsection{Insertion sort}  %%%%%%%%% INSERTION SORT %%%


    \begin{algorithm}[H] 
        \caption{InsertionSort\label{IR}}
        \KwData{A array, i indice, j indice}
        \For{ i $\leftarrow$ 2 to A.length }{
            key $\leftarrow$ A[i]\;
            j $\leftarrow$ j - 1\;
            \While{ $j>0$ \&\&  $A[j] > key$}{
                A[j+1] $\leftarrow$ A[j] \;
                j $\leftarrow$ j - 1 \;
            }
            A[j+1] $\leftarrow$ key\;
        }
        \end{algorithm}

\paragraph{Complessità Spaziale}: $\Theta(1)$ in richiede unicamente 3 interi (i, j, A.length) 
per memorizzare i valori.

\paragraph{Complessità Temporale}: \newline
- nel caso migliore: $\Theta(n)$ vettore già ordinato \newline
- nel caso peggiore: $\Theta(n^2)$ vettore ordinato al contrario 

\paragraph{Correttezza}:

\newpage

\hypertarget{merge}{} \subsection{Merge} %%%%%%%%%%% MERGE %%%
Procedura che unisce due vettori ordinati in un unico vettore ordinato. I due vettori di input non devono necessariamente avere la stessa lunghezza. 

\begin{algorithm}[H]
\caption{Merge}
\KwIn{Array $A$, indices $p$, $r$, $q$}
\KwOut{Merged array $A[p..q]$}
$i \leftarrow p$\;
$j \leftarrow r + 1$\;
$B \leftarrow$ new array of size $q - p + 1$\;
$k \leftarrow 1$\;
\While{$i < r + 1$ \textbf{and} $j < q + 1$}{
    \eIf{$A[i] \leq A[j]$}{
        $B[k] \leftarrow A[i]$\;
        $i \leftarrow i + 1$\;
    }{
        $B[k] \leftarrow A[j]$\;
        $j \leftarrow j + 1$\;
    }
    $k \leftarrow k + 1$\;
}
\If{i > r}{
    \For{$l \leftarrow j$ \KwTo $q$}{
        $B[k] \leftarrow A[l]$\;
        $k \leftarrow k + 1$\;
    }
}
\Else{
    \For{$l \leftarrow i$ \KwTo $r$}{
        $B[k] \leftarrow A[l]$\;
        $k \leftarrow k + 1$\;
    }
}
\end{algorithm}

\hypertarget{mergesort}{}\subsection{Merge sort} %%%%%%%%%%% MERGE SORT %%%%%%%%%%%
Idea: divide et impera. Divido il vettore in due parti, ordino le due parti e poi le unisco.

\begin{algorithm}[H]
\caption{MergeSort}
\KwIn{Array $A$, indices $p$, $q$}
\KwOut{Sorted array $A[p..q]$}
\If{$p < q$}{
    $r \leftarrow \floor{\frac{(p+q)}{2}}$\;
    MergeSort(A,p,r)\;
    MergeSort(A,r+1,q)\;
    Merge(A,p,q,r)\;
}
\end{algorithm}

MergeSort è un algoritmo basato su ricorsione. Necessita della procedura Merge per unire i due vettori.

\paragraph{Complessità Spaziale}: $\Theta(n)$ in quanto richiede un vettore di appoggio di dimensione n.

\paragraph{Complessità Temporale}: $\Theta(n \log n)$ in quanto il vettore viene diviso in due parti e
ogni parte viene ordinata in $\log n$ passi.

\hypertarget{buildmaxheap}{}\subsection{Build-Max-Heap (array)} %%%%%%%%% BUILD MAX HEAP %%%%%%%%%
Date n chiavi memorizzate in un array, voglio trasformare l'array in una max-heap.

\begin{algorithm}[H]
\caption{Build-Max-Heap}
\KwIn{Array $H$}
\KwOut{Max-heap $H$}
$H.heapsize \leftarrow H.length$\;
\For{$i \leftarrow \floor{\frac{H.length}{2}}$ downto 1}{
    Heapify(H,i)\;
}
\end{algorithm}

\hypertarget{heapify}{}\subsection{Heapify (array)} %%%%%%%%%% HEAPIFY %%%%%%%%%%%%
Procedura che serve a trasformare una heap in una max-heap. \newline
\textbf{pre-condizioni:} H[left(i)] e H[right(i)] sono max-heap.


\begin{algorithm}[H]
\caption{Heapify}
\KwIn{Heap $H$, indice $i$}
\KwOut{Max-heap $H$}  
$l \leftarrow$ left(i)\;
$r \leftarrow$ right(i)\;
\eIf{$l \leq H.heapsize$ \&\& $H[l] > H[i]$}{
    m $\leftarrow$ l \textit{(m è max)}\;
}{
    m $\leftarrow$ i\;
}
\If{$r \leq H.heapsize$ \&\& $H[r]>H[m]$}{
    m $\leftarrow$ r\;
}
\If{$m \neq i$}{
    scambia (H,i,m) \;
    Heapify(H,m)\;
}
\end{algorithm}

\paragraph{Complessità Spaziale}: 
\paragraph{Complessità Temporale}:
\paragraph{Correttezza}:



\hypertarget{heapsort}{}\subsection{Heap Sort} %%%%%%%%%%%% HEAP SORT %%%%%%%%%%%%%


\hypertarget{quicksort}{}\subsection{Quick Sort} %%%%%%%%%%%% QUICK SORT %%%%%%%%%%%%%
\hypertarget{partition}{\subsection{Partition}} %%%%%%%%%%%% PARTITION %%%%%%%%%%%%%
\hypertarget{selection}{\subsection{Selection}} %%%%%%%%%%%% SELECTION %%%%%%%%%%%%%

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% STRUTTURE DATI %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Strutture Dati}
\section{strutture dati lineari} %%% STRUTTURE DATI LINEARI %%%
\subsection{Array} %%%%%%%%%%%%%% ARRAY %%%
struttura dati \textbf{statica} (= suo spazio di memoria non varia) di n elementi. 
Sono a \textbf{indirizzamento diretto} e l'accesso ha un costo fisso di $\Theta (1)$

\subsection{Lista} %%%%%%%%%%%% LISTA %%%
Le liste sono strutture dati \textbf{dinamiche} (= il loro spazio di memoria può variare). 
Possono occupare spazi di
 memoria non contigui. Tra le operazioni che vogliamo fare con le liste ci sono:
 \begin{itemize}
    \item \textbf{inserimento} di un elemento in una posizione arbitraria
    \item \textbf{cancellazione} di un elemento in una posizione arbitraria
    \item \textbf{ricerca} di un elemento in una posizione arbitraria
 \end{itemize}
 
 \paragraph{liste concatenate}: ogni elemento della lista contiene un campo che punta all'elemento successivo.
 Nel caso di liste concatenate \textbf{psuh}
e \textbf{pull} hanno complessità $\Theta(1)$ in quanto conta soltanto la cella individuata dall'indice
 e \textbf{max} ha complessità $\Theta(n)$.
 
\subsection{Pila} %%%%%%%%%%%%% PILA %%%
La pila è una struttura dati \textbf{dinamica} che permette di inserire \textbf{(push)} e cancellare \textbf{(pull)}
 elementi con politica \textbf{LIFO} (Last In First Out).

\subsection{Albero Binario} %%%%%%%%%%%%%% ALBERO BINARIO %%%
Struttura dati \textbf{dinamica} costituita da nodi aventi i seguenti campi:
\begin{itemize}
    \item chiave: x.key
    \item puntatore genitore: x.parent
    \item puntatore figlio sinistro: x.left
    \item puntatore figlio destro: x.right
\end{itemize}
Nota: ovviamente se x.left punta a y, allora y.parent punta a x. 

\paragraph{albero binario completo:} Ogni nodo che non è una foglia ha esattamente due figli e tutti i 
nodi sono al livello h o h-1.

\paragraph{albero binario quasi completo:} è un albero binario completo fino al penultimo livello, l'ultimo è 
riempito da sinistra a destra.

\paragraph{altezza di un nodo:} lunghezza del cammino più lungo che va dal nodo a una foglia. Due convenzioni, in base
alla scelta dell'altezza delle foglie, che può essere 0 o 1. Nel nostro caso sarà 0. 
Un albero può avere altezza massima $n-1$.

\subsection{Code di priorità} %%%%%%%%%%% CODE DI PRIORITA %%%
Sono strutture dati \textbf{sequenziali} e \textbf{dinamiche} i cui elementi sono gestiti con politica \textbf{HPFO} (Highest Priority First Out).
 Ogni elemento è dotato di una key ma anche di una priorità.
\begin{itemize}
    \item vettori sovradimensionati
    \item liste concatenate
    \item vettori sovradimensionati ordinato per priorità
\end{itemize}

\subsection{Max-Heap} %%%%%%%%%%%%%%%% HEAP %%%
\paragraph{Heap:} Ci permettono di implementare code con priorità costo di inserimento e cancellazione pari a $O(\log n)$.

\paragraph{Max-Heap:} è un albero binario completo in cui ogni elemento ha una chiave minore o uguale di quella 
del proprio genitore.

\paragraph{proprietà} 
Data una max-heap di n nodi:
\begin{itemize}
    \item altezza: $\Theta(\log n)$
    \item chiave massima si trova nella radice
    \item ogni percorso radice-foglia ha le chiavi ordinate in modo decrescente
    \item la chiave minima si trova su una foglia
    \item le foglie sono all'incirca $\frac{n}{2}$
\end{itemize}

\paragraph{operazioni:}
voglio gestire le code di priorità, pertanto:
\begin{itemize}
    \item inserimento nuovo nodo
    \item cancellazione elemento con priorità massima
    \item ricerca del nodo con priorità massima
    \item modifica della priorità di un nodo
\end{itemize}

\paragraph{implementazione:} per implementare una max-heap posso usare:
\begin{itemize}
    \item \textbf{albero}: struttura dati dinamica 
    \item \textbf{vettore sovradimensionato}: struttura dati statica
\end{itemize}

\paragraph{procedure di base:}

\begin{tabbing}
\begin{lstlisting}
    figlio sinistro:

    left(i){
        return 2i
        } 
\end{lstlisting}
\
\begin{lstlisting}
    figlio destro:

    right(i){
        return 2i + 1
        }
\end{lstlisting}
\begin{lstlisting}
    nodo genitore:

    parent(i){
        return $\floor{\frac{i}{2}}$
        }
\end{lstlisting}
    
\end{tabbing}


\end{document}