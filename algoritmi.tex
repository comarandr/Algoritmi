\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx} % Required for inserting images
%before \begin
\usepackage{amssymb} %per i simboli matematici
\usepackage{mathtools} %per simboli 
\usepackage{listings} %per scrivere codice
\usepackage[boxruled,vlined]{algorithm2e}
\lstset{
  basicstyle=\ttfamily,
  mathescape
}
\usepackage{color} %per colorare il codice
\usepackage{hyperref} %per i link
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% COPERTINA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Algoritmi \& Strutture Dati}
\author{Andrea Comar}
\date{October 2024}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CONCETTI MATEMATICI %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Concetti Matematici}
\section{Notazione asintotica} %%% NOTAZIONE ASINTOTICA %%%
Strumento per confrontare quale funzioni divergono all'infinito più velocemente. Metodo di confronto 
tra funzioni di costo degli algoritmi. Caratteristiche:
\begin{itemize}
    \item $f: \mathbb{N} \rightarrow \mathbb{R^+}$
    \item funzioni \textbf{monotone crescenti}
    \item $lim_{n \rightarrow \infty} \ f(n) = \infty$ (divergenti)
\end{itemize}

In breve la notazione asintotica si basa su tre simboli:
\begin{itemize}
    \item $O$ (O-grande): rappresenta il caso peggiore, ovvero il \textbf{limite asintotico superiore}. ~ "cresce al più come"
    \item $\Omega$ (Omega): rappresenta il caso migliore, ovvero il \textbf{limite asintotico inferiore} ~ "cresce al meno come"
    \item $\theta$ (theta): rappresenta il caso medio, ovvero il \textbf{limite asintotico stretto} ~ "stesso ordine di grande"
\end{itemize}
La notazione asintotica si fonda sul concetto di limite, in particolare sul \textbf{limite del rapporto}. Di base possiamo riscri


\subsection{Notazione O-grande (e o-piccolo)} %%%%%%%%%%%%%%%%%%%%%%% NOTAZIONE O-GRANDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Notazione O-grande $O$} Abbiamo due definizioni equivalenti:
\begin{itemize}
\item $O(g(n))=\{f(n)| \ \exists c > 0 \ \exists \bar{n} \ \forall n \geq \bar{n} \ f(n) \leq c \cdot g(N)\}$ 
\item Date $f,g : \mathbb{N} \rightarrow \mathbb{R^+}$ \textbf{monotone crescenti}, diciamo che $f(n) \in O(g(n))$ se $\exists c > 0 \ e \ \exists \bar{n} : \forall n \geq \bar{n} \ f(n) \leq c \cdot g(n)$
\end{itemize}
Di base entrambe fanno riferimento al concetto di \textbf{limite del rapporto} 
\begin{itemize}
    \item $\displaystyle \limsup_{n \to \infty} \lvert \frac{f(n)}{g(n)} \rvert < \infty \Leftrightarrow f(n) = O(g(n))$ 
\end{itemize}
Diciamo che g(n) domina f(n), ovvero f(n) ha un ordine di grandezza minore o uguale a g(n).
\paragraph{notazione o-piccolo $o$} Se nelle definizioni invece di $\exists c$ vale per $\forall c$  si parla di notazione o-piccolo. Quindi vale il seguente limite:
\begin{itemize}
    \item $\displaystyle \lim_{n \rightarrow \infty} \frac{f(n)}{g(n)} = 0 \Leftrightarrow f(n) = o(g(n))$
\end{itemize}
Di conseguenza $f(n) = o(g(n)) \Rightarrow f(n) = O(g(n))$, NON il contrario.
\subsection{Notazione Omega-grande (e omega-piccolo)} %%%%%%%%%%%%%%%%%% NOTAZIONE OMEGA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Notazione Omega-grande $\Omega$} Abbiamo due definizioni equivalenti:
\begin{itemize}
\item $\Omega(g(n))=\{f(n)| \ \exists c > 0 \ \exists \bar{n} \in \mathbb{N} \ \forall n \geq \bar{n} \ f(n) \geq c \cdot g(N)\}$ 
\item Date $f,g : \mathbb{N} \rightarrow \mathbb{R^+}$ \textbf{monotone crescenti}, diciamo che $f(n) \in \Omega(g(n))$ se $\exists c > 0 \ e \ \exists \bar{n} : \forall n \geq \bar{n} \ f(n) \geq c \cdot g(n)$
\end{itemize}
Di base entrambe fanno riferimento al concetto di \textbf{limite del rapporto}
\begin{itemize}
    \item $\displaystyle \liminf_{n \rightarrow \infty} \lvert \frac{f(n)}{g(n)} \rvert > 0 \Leftrightarrow f(n) = \Omega(g(n))$
\end{itemize}
\paragraph{notazione omega-piccolo $\omega$} Se nelle definizioni invece di $\exists c$ vale per $\forall c$  si parla di notazione omega-piccolo. Quindi vale il seguente limite:
\begin{itemize}
    \item $\displaystyle \lim_{n\to\infty} \frac{f(n)}{g(n)} = \infty \Leftrightarrow f(n) = \omega(g(n))$
\end{itemize}
Di conseguenza $f(n) = \omega(g(n)) \Rightarrow f(n) = \Omega(g(n))$, NON il contrario.

\subsection{Notazione Theta} %%%%%%%%%% NOTAZIONE THETA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}
\item $\theta(g(n))=\{f(n)| \ \exists c_1, c_2 > 0 \ \exists \bar{n} \in \mathbb{N} \ \forall n \geq \bar{n} \ c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)\}$
\item Date $f,g : \mathbb{N} \rightarrow \mathbb{R^+}$ \textbf{monotone crescenti}, diciamo che $f(n) \in \theta(g(n))$ se $\exists c_1, c_2 > 0 \ e \ \exists \bar{n} : \forall n \geq \bar{n} \ c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)$
\end{itemize}

Di base entrambe fanno riferimento al concetto di \textbf{limite del rapporto}
\begin{itemize}
    \item $\displaystyle 0 < \liminf_{n\to\infty} \lvert \frac{f(n)}{g(n)}\rvert \leq \limsup_{n\to\infty}\lvert \frac{f(n)}{g(n)}\rvert \leq \infty$
\end{itemize}

\paragraph{notazione $\sim$}  Se le due funzioni sono sia $o$ che $\theta$ allora si può scrivere $f(n) \sim g(n)$ e vale che:
\begin{itemize}
    \item $\displaystyle \lim_{n \rightarrow \inf} \frac{f(n)}{g(n)} = c , c \neq 0 \in \mathbb{R} \Leftrightarrow f(n) \sim g(n)$
\end{itemize}
Di conseguenza $f(n) \sim g(n) \Rightarrow f(n) = \theta(g(n))$, NON il contrario. \newline
NOTA: per parlare di equivalenza asintotica $c$ dovrebbe essere esattamente uguale a 1.
\newpage

\subsection{Proprietà} %%%%%%%%%%%%%%%% PROPRIETA' %%%%%%%%%%%%%%%%%%%%%%%%%%%%
Se f(n) è $O$ di g(n) allora g(n) è $\Omega$ di f(n). Significa che g(n) cresce di più asintoticamente.
\begin{itemize}
\item $f(n) \in O(g(n)) \ \Leftrightarrow \ g(n) \in \Omega(f(n))$
\end{itemize}
Se f(n) cresce allo stesso modo di g(n), g(n) rappresenta sia il limite superiore che inferiore.
\begin{itemize}
\item $f(n) \in \theta(g(n)) \ \Leftrightarrow \ f(n) \in O(g(n)) \ e \ f(n) \in \Omega(g(n))$
\end{itemize}
Analogamente per la notazione o-piccolo e omega-piccolo:
\begin{itemize}
\item $f(n) \in o(g(n)) \ \Leftrightarrow \ g(n) \in \omega(f(n))$
\end{itemize}

\subsection{Comportamento rispetto alle operazioni} %%%%%%%%%%%%%%%%% REGOLE %%%%%%%%%%%%%%%%%%
Le seguenti regole valgono indistimamente per $O$, $\Omega$ e $\theta$, si ereditano dalle proprietà dei limiti.

\paragraph{Somma}: 
\begin{itemize}
    \item $O(f(n)) + O(g(n)) = O(f(n) + g(n))$
    \item $\Omega(f(n)) + \Omega(g(n)) = \Omega(f(n) + g(n))$
    \item $\theta(f(n)) + \theta(g(n)) = \theta(f(n) + g(n))$
\end{itemize}

\paragraph{Prodotto}:

\begin{itemize}
    \item $O(f(n)) \cdot O(g(n)) = O(f(n) \cdot g(n))$
    \item $\Omega(f(n)) \cdot \Omega(g(n)) = \Omega(f(n) \cdot g(n))$
    \item $\theta(f(n)) \cdot \theta(g(n)) = \theta(f(n) \cdot g(n))$
\end{itemize}

Le precedenti regole NON valgono per operazioni di sottrazione e divisione.

\paragraph{Costante}:
\begin{itemize}
    \item $O(c \cdot f(n)) = O(f(n))$, $\forall c \in \mathbb{R}_0$
    \item $\Omega(c \cdot f(n)) = \Omega(f(n))$
    \item $\theta(c \cdot f(n)) = \theta(f(n))$
\end{itemize}

\begin{itemize}
    \item $O(f(n)) = O(g(n)) \ \Leftrightarrow \ f(n) \in \theta(g(n))$
    \item $O(f(n)) = O(g(n)) \ \Leftrightarrow \ f(n) \in \theta(g(n))$
\end{itemize}
\newpage

\section{Cenni utili sui limiti}

\section{Stime di Somme}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ALGORITMI %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Algoritmi}
\section{Algoritmi di ordinamento}
\paragraph{PROBLEMA} Problema data una sequenza a1, a2, ..., an di numeri, trovare una permutazione tale che 
$a1 \leq a2  \leq ... \leq an$. \newline
Soluzioni:
\subsection{Insertion sort}  %%%%%%%%% INSERTION SORT %%%


    \begin{algorithm}[H] 
        \caption{InsertionSort\label{IR}}
        \KwData{A array, i indice, j indice}
        \For{ i $\leftarrow$ 2 to A.length }{
            key $\leftarrow$ A[i]\;
            j $\leftarrow$ j - 1\;
            \While{ $j>0$ \&\&  $A[j] > key$}{
                A[j+1] $\leftarrow$ A[j] \;
                j $\leftarrow$ j - 1 \;
            }
            A[j+1] $\leftarrow$ key\;
        }
        \end{algorithm}

\paragraph{Complessità Spaziale}: $\theta(1)$ in richiede unicamente 3 interi (i, j, A.length) 
per memorizzare i valori.

\paragraph{Complessità Temporale}: \newline
- nel caso migliore: $\theta(n)$ vettore già ordinato \newline
- nel caso peggiore: $\theta(n^2)$ vettore ordinato al contrario 

\paragraph{Correttezza}:

\newpage

\subsection{Merge} %%%%%%%%%%% MERGE %%%
Procedura che unisce due vettori ordinati in un unico vettore ordinato. I due vettori di input non devono necessariamente avere la stessa lunghezza. 

\begin{algorithm}[H]
\caption{Merge}
\KwIn{Array $A$, indices $p$, $r$, $q$}
\KwOut{Merged array $A[p..q]$}
$i \leftarrow p$\;
$j \leftarrow r + 1$\;
$B \leftarrow$ new array of size $q - p + 1$\;
$k \leftarrow 1$\;
\While{$i < r + 1$ \textbf{and} $j < q + 1$}{
    \eIf{$A[i] \leq A[j]$}{
        $B[k] \leftarrow A[i]$\;
        $i \leftarrow i + 1$\;
    }{
        $B[k] \leftarrow A[j]$\;
        $j \leftarrow j + 1$\;
    }
    $k \leftarrow k + 1$\;
}
\If{i > r}{
    \For{$l \leftarrow j$ \KwTo $q$}{
        $B[k] \leftarrow A[l]$\;
        $k \leftarrow k + 1$\;
    }
}
\Else{
    \For{$l \leftarrow i$ \KwTo $r$}{
        $B[k] \leftarrow A[l]$\;
        $k \leftarrow k + 1$\;
    }
}
\end{algorithm}

\subsection{Merge sort} %%%%%%%%%%% MERGE SORT %%%%%%%%%%%
Idea: divide et impera. Divido il vettore in due parti, ordino le due parti e poi le unisco.

\begin{algorithm}[H]
\caption{MergeSort}
\KwIn{Array $A$, indices $p$, $q$}
\KwOut{Sorted array $A[p..q]$}
\If{$p < q$}{
    $r \leftarrow \floor{\frac{(p+q)}{2}}$\;
    MergeSort(A,p,r)\;
    MergeSort(A,r+1,q)\;
    Merge(A,p,q,r)\;
}
\end{algorithm}

MergeSort è un algoritmo basato su ricorsione. Necessita della procedura Merge per unire i due vettori.

\paragraph{Complessità Spaziale}: $\theta(n)$ in quanto richiede un vettore di appoggio di dimensione n.

\paragraph{Complessità Temporale}: $\theta(n \log n)$ in quanto il vettore viene diviso in due parti e
ogni parte viene ordinata in $\log n$ passi.

\subsection{Heapify (array)} %%%%%%%%%% HEAPIFY %%%%%%%%%%%%
Procedura che serve a trasformare una heap in una max-heap. \newline
\textbf{pre-condizioni:} H[left(i)] e H[right(i)] sono max-heap.


\begin{algorithm}[H]
\caption{Heapify}
\KwIn{Heap $H$, indice $i$}
\KwOut{Max-heap $H$}  
$l \leftarrow$ left(i)\;
$r \leftarrow$ right(i)\;
\eIf{$l \leq H.heapsize$ \&\& $H[l] > H[i]$}{
    m $\leftarrow$ l \textit{(m è max)}\;
}{
    m $\leftarrow$ i\;
}
\If{$r \leq H.heapsize$ \&\& $H[r]>H[m]$}{
    m $\leftarrow$ r\;
}
\If{$m \neq i$}{
    scambia (H,i,m) \;
    Heapify(H,m)\;
}
\end{algorithm}

\paragraph{Complessità Spaziale}: 
\paragraph{Complessità Temporale}:
\paragraph{Correttezza}:

\subsection{Build-Max-Heap (array)} %%%%%%%%% BUILD MAX HEAP %%%%%%%%%
Date n chiavi memorizzate in un array, voglio trasformare l'array in una max-heap.

\begin{algorithm}[H]
\caption{Build-Max-Heap}
\KwIn{Array $H$}
\KwOut{Max-heap $H$}
$H.heapsize \leftarrow H.length$\;
\For{$i \leftarrow \floor{\frac{H.length}{2}}$ downto 1}{
    Heapify(H,i)\;
}
\end{algorithm}



\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% STRUTTURE DATI %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Strutture Dati}
\section{strutture dati lineari} %%% STRUTTURE DATI LINEARI %%%
\subsection{Array} %%%%%%%%%%%%%% ARRAY %%%
struttura dati \textbf{statica} (= suo spazio di memoria non varia) di n elementi. 
Sono a \textbf{indirizzamento diretto} e l'accesso ha un costo fisso di $\theta (1)$

\subsection{Lista} %%%%%%%%%%%% LISTA %%%
Le liste sono strutture dati \textbf{dinamiche} (= il loro spazio di memoria può variare). 
Possono occupare spazi di
 memoria non contigui. Tra le operazioni che vogliamo fare con le liste ci sono:
 \begin{itemize}
    \item \textbf{inserimento} di un elemento in una posizione arbitraria
    \item \textbf{cancellazione} di un elemento in una posizione arbitraria
    \item \textbf{ricerca} di un elemento in una posizione arbitraria
 \end{itemize}
 
 \paragraph{liste concatenate}: ogni elemento della lista contiene un campo che punta all'elemento successivo.
 Nel caso di liste concatenate \textbf{psuh}
e \textbf{pull} hanno complessità $\theta(1)$ in quanto conta soltanto la cella individuata dall'indice
 e \textbf{max} ha complessità $\theta(n)$.
 
\subsection{Pila} %%%%%%%%%%%%% PILA %%%
La pila è una struttura dati \textbf{dinamica} che permette di inserire \textbf{(push)} e cancellare \textbf{(pull)}
 elementi con politica \textbf{LIFO} (Last In First Out).

\subsection{Albero Binario} %%%%%%%%%%%%%% ALBERO BINARIO %%%
Struttura dati \textbf{dinamica} costituita da nodi aventi i seguenti campi:
\begin{itemize}
    \item chiave: x.key
    \item puntatore genitore: x.parent
    \item puntatore figlio sinistro: x.left
    \item puntatore figlio destro: x.right
\end{itemize}
Nota: ovviamente se x.left punta a y, allora y.parent punta a x. 

\paragraph{albero binario completo:} Ogni nodo che non è una foglia ha esattamente due figli e tutti i 
nodi sono al livello h o h-1.

\paragraph{albero binario quasi completo:} è un albero binario completo fino al penultimo livello, l'ultimo è 
riempito da sinistra a destra.

\paragraph{altezza di un nodo:} lunghezza del cammino più lungo che va dal nodo a una foglia. Due convenzioni, in base
alla scelta dell'altezza delle foglie, che può essere 0 o 1. Nel nostro caso sarà 0. 
Un albero può avere altezza massima $n-1$.

\subsection{Code di priorità} %%%%%%%%%%% CODE DI PRIORITA %%%
Sono strutture dati \textbf{sequenziali} e \textbf{dinamiche} i cui elementi sono gestiti con politica \textbf{HPFO} (Highest Priority First Out).
 Ogni elemento è dotato di una key ma anche di una priorità.
\begin{itemize}
    \item vettori sovradimensionati
    \item liste concatenate
    \item vettori sovradimensionati ordinato per priorità
\end{itemize}

\subsection{Max-Heap} %%%%%%%%%%%%%%%% HEAP %%%
\paragraph{Heap:} Ci permettono di implementare code con priorità costo di inserimento e cancellazione pari a $O(\log n)$.

\paragraph{Max-Heap:} è un albero binario completo in cui ogni elemento ha una chiave minore o uguale di quella 
del proprio genitore.

\paragraph{proprietà} 
Data una max-heap di n nodi:
\begin{itemize}
    \item altezza: $\theta(\log n)$
    \item chiave massima si trova nella radice
    \item ogni percorso radice-foglia ha le chiavi ordinate in modo decrescente
    \item la chiave minima si trova su una foglia
    \item le foglie sono all'incirca $\frac{n}{2}$
\end{itemize}

\paragraph{operazioni:}
voglio gestire le code di priorità, pertanto:
\begin{itemize}
    \item inserimento nuovo nodo
    \item cancellazione elemento con priorità massima
    \item ricerca del nodo con priorità massima
    \item modifica della priorità di un nodo
\end{itemize}

\paragraph{implementazione:} per implementare una max-heap posso usare:
\begin{itemize}
    \item \textbf{albero}: struttura dati dinamica 
    \item \textbf{vettore sovradimensionato}: struttura dati statica
\end{itemize}

\paragraph{procedure di base:}

\begin{tabbing}
\begin{lstlisting}
    figlio sinistro:

    left(i){
        return 2i
        } 
\end{lstlisting}
\
\begin{lstlisting}
    figlio destro:

    right(i){
        return 2i + 1
        }
\end{lstlisting}
\begin{lstlisting}
    nodo genitore:

    parent(i){
        return $\floor{\frac{i}{2}}$
        }
\end{lstlisting}
    
\end{tabbing}


\end{document}